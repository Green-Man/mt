\chapter{Theory}
\label{chapter:theory}

\section{Monte-Carlo integration with importance sampling}
\label{section:importance_sampling}
According to the theory of the light transport, the behaviour of the light can be expressed by the
equation of radiative transfer in homogeneous media \cite{Lafortune:1996:RPM:275458.275468}:
\begin{equation}
\label{rte}
L_o(\vec{x_0}, \Theta) = \int_{A} \int_{\Omega} f(\vec{x}_i-\vec{x}_o,\omega_o,\omega_i)
L_i(\vec{x}_i-\vec{x}_o, \omega_o, \omega_i) d\omega_i e^{-ks} + L_e(\vec{x}_i-\vec{x}_o, \omega_o)
e^{-kd}
\end{equation}

In this chapter we can proceed without detailed description of every part of the equation \ref{rte}.
The main idea at this point is that computing of the relation between incoming and outgoing radiance
requires double integration of complicated and almost arbitrary functions and, in general, has no
analytical solution. This integral formulation is a good candidate for evaluation using Monte-Carlo
technique.

To evaluate the arbitrary integral of the form:
\[
I = \int_\Theta f(x) dx
\]
we have to evaluate the integrand function at the independent randomly sampled points $x_i$ such
that $f_i = f(x_i)$. In case if the probability density function of the sampling is $p(x_i)$ and $N$
number of samples is taken, the estimated value of the integral is \cite{hammersley64}:
\begin{equation}
\label{mc_estimator}
\hat{I}=\frac{1}{N}\sum_{i=1}^N\frac{f(x_i)}{p(x_i)}
\end{equation}

In special case of uniformly sampled function the $p(x_i)=1$ and the Monte Carlo estimator
\ref{mc_estimator} has a form of quadrature rule where the sampling points are chosen randomly
instead of uniform grid:
\begin{equation}
\label{uniform_estimator}
\hat{I}=\frac{1}{N}\sum_{i=1}^N f(x_i)
\end{equation}

The Monte Carlo integration is the main method of estimating the light transport integrals due to
it's robustness regardless of the number of dimensions and the form of the integrand
\cite{Veach:1998:RMC:927297}

The uniform Monte Carlo estimator is often modified to reduce variance due to the slow $O(\sqrt{N})$
convergence. It is desirable to find the sampling distribution $p(x_i)$ such that it has as close a
possible form to the resulting integral $I$. This technique is called \emph{importance sampling}. In
path tracing context it requites the sampling of the paths which carry the most of the light
contribution to the resulting image. The problem of finding the right sampling for arbitrary
probability density function can be a complicated task in general. One practical problem of this
kind and possible solutions of it are discussed in the \ref{section:burley_importance} section of
this thesis.

\input{chapters/theory/mis}

\subsection{Russian roulette}
\label{subsection:rr}
Russian Roulette was first described in \cite{hammersley64} as a method for termination of the
random walks in neutron transport calculations. Even though it is used by computer graphics Monte
Carlo estimators to produce unbiased result in shorter time, it is not a variance reduction
technique in strict mathematical sense.

The problem of long path termination can be naively solved by threshold. In this approach the
path integration is stopped after the path weight reaches some particular small threshold value and
contribution of such a path will no longer be noticeable. The main disadvantage of such method is
the it always introduces a bias to the final result if the path termination threshold is
considerably large.

Strictly speaking, it it even increases the variance of the estimator. But reduces to cost of sampling in
average \cite{Veach:1998:RMC:927297}, \cite{Csi03variancereduction}

Russian roulette is an indispensable technique in transport calculations, since it allows otherwise
infinite random walks to be terminated without bias \cite{Veach:1998:RMC:927297}

\ldots

\section{Light simulation in participating media}
\label{section:light_simulation_theory}
\subsection{Emission, Absorption and Scattering}

\subsection{Isotropic and Anisotropic phase functions}
\label{section:phasefunction}

The simplest isotropic phase function i.e. the probability density of the scattering in the given
direction has the form:
\[
p(\Theta) = \frac{1}{4\pi}
\]
which of course does not depends on the angel and is constant in any direction.

The form of the phase function in the anisotropic scattering becomes more complex. The number of
sources have shown \cite{0031-9155-51-17-N04}, \cite{Gkioulekas:2013:URP:2516971.2516972} that the
Heynye-Greenstein function fits reasonably well for approximation complex phase function of many
organic or artificial materials:
\begin{align}
\label{eq:hg_pdf_theory}
p(\Theta) = \frac{1}{4\pi}\cdot\frac{1-g^2}{1+g^2-2g(\cos{\Theta})^{3/2}}
\end{align}
where $\Theta$ is an angle between incident and scattered directions of the particle, $g$ is the
anisotropy factor. $g$ has it's values in the range from -1 to 1 for back or front scattering
materials respectively. The anisotropy factor describes the characteristic number of the scattering
events after which the information of the initial incident direction is lost
\cite{wang2007biomedical}.

Even though there is a common approximation for reduced scattering coefficient:
\[
\sigma\prime_s = \sigma_s(1 - g)
\]
the sections regarding Diffusion Approximation in this work only describe rendering of the isotropic
materials.

Despite the fact that Heynye-Greenstein phase function is widely used in many rendering application
the work \cite{Gkioulekas:2013:IVR:2508363.2508377} showed a big user study pointing some failing
cases of this approximation due to the lack of generality of the Heynye-Greenstein function. Another
conclusion from this research is that anisotropy parameter has higly non-linear effect on the
rendered output and it suggested to be exposed to the users as $g^2$.

\input{chapters/theory/diffusion_approximation}